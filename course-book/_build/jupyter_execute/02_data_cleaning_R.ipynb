{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b86076f-0c66-4aaf-a9c5-7d976612b012",
   "metadata": {},
   "source": [
    "```{thebe-button}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43254fd-a1de-4dbb-9f04-c80c9d32b577",
   "metadata": {},
   "source": [
    "# 02: Data Cleaning\n",
    "\n",
    "**Objective:** Identify and handle missing or invalid values, detect outliers, and standardize data for our recidivism dataset.\n",
    "\n",
    "**Key Steps:**\n",
    "\n",
    "<table width=\"100%\">\n",
    "  <tr>\n",
    "    <td style=\"vertical-align: top; text-align: left; width: 60%; padding-right: 20px;\">\n",
    "      <ol style=\"font-size: 20px; line-height: 1.4;\">\n",
    "        <li>Identify &amp; quantify missing data</li>\n",
    "        <li>Handle missing values (imputation, removal, flagging)</li>\n",
    "        <li>Validate &amp; correct data types</li>\n",
    "        <li>Detect &amp; treat outliers</li>\n",
    "        <li>Standardize &amp; normalize</li>\n",
    "        <li>Document transformations</li>\n",
    "      </ol>\n",
    "    </td>\n",
    "    <td style=\"vertical-align: top; text-align: left; width: 40%;\">\n",
    "      <!-- relative path to cleaning.png -->\n",
    "      <img src=\"../slides/cleaning.png\" alt=\"Data Cleaning Image\" width=\"1000\" />\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "---\n",
    "<audio controls src=\"../audio/Cleaning.m4a\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2ee20a-a11e-46bb-a55c-430fa6001f97",
   "metadata": {},
   "source": [
    "Now that we’ve laid out our data‑cleaning roadmap, let’s put it into practice with a real dataset. For the rest of this lesson, we’ll work with the **COMPAS recidivism data** (`compas‑scores‑raw.csv`), which contains demographic and risk‑assessment scores for individuals screened by the COMPAS tool. \n",
    "\n",
    "We’ll start by running through each cleaning step in **R**, then you are encouraged to repeat the same process in **Python** so you can see both workflows side by side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b4df10-be09-4085-9494-04ccbc7e077d",
   "metadata": {},
   "source": [
    "## R\n",
    "\n",
    "Since this is your first time, you’ll need to download all of the little helper programs (called “packages”) we’ll use—just run one simple command to get them all at once:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0433faa9-9af5-4da1-9a46-387697bd59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing packages into 'C:/Users/demoore/AppData/Local/R/win-library/4.4'\n",
      "(as 'lib' is unspecified)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"dependency 'RDCOMClient' is not available\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'tidyverse' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'lubridate' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'DescTools' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'corrplot' successfully unpacked and MD5 sums checked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\demoore\\AppData\\Local\\Temp\\RtmpKyML6I\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "# only run this block your first time doing this training.\n",
    "\n",
    "\n",
    "pkgs <- scan(\"../requirements_R.txt\", what = \"\")\n",
    "install.packages(\n",
    "  pkgs,\n",
    "  repos        = \"https://cloud.r-project.org\",\n",
    "  dependencies = TRUE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e571a548-0a04-4de6-9fe1-18b518456c6a",
   "metadata": {},
   "source": [
    "#### Loading the tidyverse Package\n",
    "\n",
    "Before we can start working with our data in R, we need to load a set of helpful tools called the **tidyverse**. The tidyverse gives us simple, consistent commands for:\n",
    "\n",
    "- **Reading** data files (for example, Excel or CSV tables)  \n",
    "- **Filtering** and **arranging** rows of data  \n",
    "- **Summarizing** and **grouping** information  \n",
    "- **Creating** basic charts and graphs  \n",
    "\n",
    "Even if you’ve never done any data work before, this one line will make all of those functions available:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f9c39b-205a-4d55-aad4-c5af9c6a4ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tidyverse' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tibble' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'tidyr' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'readr' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'purrr' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'dplyr' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'stringr' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'forcats' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'lubridate' was built under R version 4.4.3\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.1     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.4     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2ab41-ff12-470f-bfef-4a96bb060f05",
   "metadata": {},
   "source": [
    "##### It’s OK to See Warning Messages\n",
    "\n",
    "When you load a package in R, you might see warnings like:\n",
    "```r\n",
    "Warning message:\n",
    "\"package 'tidyverse' was built under R version 4.4.3\n",
    "```\n",
    "\n",
    "These messages are harmless—they simply mean the package was compiled under a slightly different R release than the one you’re using. They do **not** indicate an error in your code or your analysis.\n",
    "\n",
    "You can safely ignore these warnings and continue working:\n",
    "- Your functions will still run as expected  \n",
    "- Your data cleaning and analysis steps are unaffected  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddb4344-5f10-4297-b2b2-a8509510039b",
   "metadata": {},
   "source": [
    "#### Now, once you run library(tidyverse), you can:\n",
    "\n",
    "- Use `read_csv(\"myfile.csv\")` to import your data  \n",
    "- Use `filter()` to narrow down the rows you care about  \n",
    "- Use `select()` to pick the columns you want to keep  \n",
    "- And much more—all with clear, English‑like commands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee8250-c910-4ba3-9f1f-aa5fd7383673",
   "metadata": {},
   "source": [
    "### 2.1 Identify & Quantify Missing Data\n",
    "\n",
    "First, load the data and get a sense of where values are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f1c026-5a49-450e-876a-3d5af65804c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m24272\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m24\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[31mchr\u001b[39m (15): Agency_Text, LastName, FirstName, MiddleName, Sex_Code_Text, Ethni...\n",
      "\u001b[32mdbl\u001b[39m  (9): Person_ID, AssessmentID, Case_ID, ScaleSet_ID, RecSupervisionLevel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "# Load the COMPAS scores data into R\n",
    "df <- read_csv(\"../data/compas_scores_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7fb48d-924a-4819-a0cb-b46139703a9f",
   "metadata": {},
   "source": [
    "Finally, we call head(df) on the DataFrame to display the first few rows. This gives us a quick peek at the structure and contents of our dataset, including column names and sample values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f36e97-61f4-4ff9-9087-2f7b7b96b491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 24</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Person_ID</th><th scope=col>AssessmentID</th><th scope=col>Case_ID</th><th scope=col>Agency_Text</th><th scope=col>LastName</th><th scope=col>FirstName</th><th scope=col>MiddleName</th><th scope=col>Sex_Code_Text</th><th scope=col>Ethnic_Code_Text</th><th scope=col>ScaleSet_ID</th><th scope=col>⋯</th><th scope=col>MaritalStatus</th><th scope=col>RecSupervisionLevel</th><th scope=col>RecSupervisionLevelText</th><th scope=col>Scale_ID</th><th scope=col>DisplayText</th><th scope=col>RawScore</th><th scope=col>DecileScore</th><th scope=col>ScoreText</th><th scope=col>AssessmentType</th><th scope=col>Age</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>50844</td><td>57167</td><td>51950</td><td>PRETRIAL</td><td>Fisher  </td><td>Kevin    </td><td>NA    </td><td>Male  </td><td>Caucasian       </td><td>22</td><td>⋯</td><td>Single           </td><td>1</td><td>Low   </td><td>18</td><td>Risk of Failure to Appear</td><td>15.00</td><td>1</td><td>Low </td><td>New</td><td>20</td></tr>\n",
       "\t<tr><td>50848</td><td>57174</td><td>51956</td><td>PRETRIAL</td><td>KENDALL </td><td>KEVIN    </td><td>NA    </td><td>Male  </td><td>Caucasian       </td><td>22</td><td>⋯</td><td>Married          </td><td>1</td><td>Low   </td><td>18</td><td>Risk of Failure to Appear</td><td>19.00</td><td>3</td><td>Low </td><td>New</td><td>28</td></tr>\n",
       "\t<tr><td>50855</td><td>57181</td><td>51963</td><td>PRETRIAL</td><td>DAYES   </td><td>DANIEL   </td><td>NA    </td><td>Male  </td><td>African-American</td><td>22</td><td>⋯</td><td>Single           </td><td>4</td><td>High  </td><td> 8</td><td>Risk of Recidivism       </td><td> 0.18</td><td>8</td><td>High</td><td>New</td><td>18</td></tr>\n",
       "\t<tr><td>50855</td><td>57181</td><td>51963</td><td>PRETRIAL</td><td>DAYES   </td><td>DANIEL   </td><td>NA    </td><td>Male  </td><td>African-American</td><td>22</td><td>⋯</td><td>Single           </td><td>4</td><td>High  </td><td>18</td><td>Risk of Failure to Appear</td><td>13.00</td><td>1</td><td>Low </td><td>New</td><td>18</td></tr>\n",
       "\t<tr><td>50850</td><td>57176</td><td>51958</td><td>PRETRIAL</td><td>Debe    </td><td>Mikerlie </td><td>George</td><td>Female</td><td>African-American</td><td>22</td><td>⋯</td><td>Significant Other</td><td>2</td><td>Medium</td><td>18</td><td>Risk of Failure to Appear</td><td>11.00</td><td>1</td><td>Low </td><td>New</td><td>18</td></tr>\n",
       "\t<tr><td>50839</td><td>57162</td><td>51945</td><td>PRETRIAL</td><td>McLaurin</td><td>Stephanie</td><td>Nicole</td><td>Female</td><td>African-American</td><td>22</td><td>⋯</td><td>Single           </td><td>1</td><td>Low   </td><td>18</td><td>Risk of Failure to Appear</td><td>16.00</td><td>2</td><td>Low </td><td>New</td><td>27</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 24\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " Person\\_ID & AssessmentID & Case\\_ID & Agency\\_Text & LastName & FirstName & MiddleName & Sex\\_Code\\_Text & Ethnic\\_Code\\_Text & ScaleSet\\_ID & ⋯ & MaritalStatus & RecSupervisionLevel & RecSupervisionLevelText & Scale\\_ID & DisplayText & RawScore & DecileScore & ScoreText & AssessmentType & Age\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <dbl> & ⋯ & <chr> & <dbl> & <chr> & <dbl> & <chr> & <dbl> & <dbl> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 50844 & 57167 & 51950 & PRETRIAL & Fisher   & Kevin     & NA     & Male   & Caucasian        & 22 & ⋯ & Single            & 1 & Low    & 18 & Risk of Failure to Appear & 15.00 & 1 & Low  & New & 20\\\\\n",
       "\t 50848 & 57174 & 51956 & PRETRIAL & KENDALL  & KEVIN     & NA     & Male   & Caucasian        & 22 & ⋯ & Married           & 1 & Low    & 18 & Risk of Failure to Appear & 19.00 & 3 & Low  & New & 28\\\\\n",
       "\t 50855 & 57181 & 51963 & PRETRIAL & DAYES    & DANIEL    & NA     & Male   & African-American & 22 & ⋯ & Single            & 4 & High   &  8 & Risk of Recidivism        &  0.18 & 8 & High & New & 18\\\\\n",
       "\t 50855 & 57181 & 51963 & PRETRIAL & DAYES    & DANIEL    & NA     & Male   & African-American & 22 & ⋯ & Single            & 4 & High   & 18 & Risk of Failure to Appear & 13.00 & 1 & Low  & New & 18\\\\\n",
       "\t 50850 & 57176 & 51958 & PRETRIAL & Debe     & Mikerlie  & George & Female & African-American & 22 & ⋯ & Significant Other & 2 & Medium & 18 & Risk of Failure to Appear & 11.00 & 1 & Low  & New & 18\\\\\n",
       "\t 50839 & 57162 & 51945 & PRETRIAL & McLaurin & Stephanie & Nicole & Female & African-American & 22 & ⋯ & Single            & 1 & Low    & 18 & Risk of Failure to Appear & 16.00 & 2 & Low  & New & 27\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 24\n",
       "\n",
       "| Person_ID &lt;dbl&gt; | AssessmentID &lt;dbl&gt; | Case_ID &lt;dbl&gt; | Agency_Text &lt;chr&gt; | LastName &lt;chr&gt; | FirstName &lt;chr&gt; | MiddleName &lt;chr&gt; | Sex_Code_Text &lt;chr&gt; | Ethnic_Code_Text &lt;chr&gt; | ScaleSet_ID &lt;dbl&gt; | ⋯ ⋯ | MaritalStatus &lt;chr&gt; | RecSupervisionLevel &lt;dbl&gt; | RecSupervisionLevelText &lt;chr&gt; | Scale_ID &lt;dbl&gt; | DisplayText &lt;chr&gt; | RawScore &lt;dbl&gt; | DecileScore &lt;dbl&gt; | ScoreText &lt;chr&gt; | AssessmentType &lt;chr&gt; | Age &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 50844 | 57167 | 51950 | PRETRIAL | Fisher   | Kevin     | NA     | Male   | Caucasian        | 22 | ⋯ | Single            | 1 | Low    | 18 | Risk of Failure to Appear | 15.00 | 1 | Low  | New | 20 |\n",
       "| 50848 | 57174 | 51956 | PRETRIAL | KENDALL  | KEVIN     | NA     | Male   | Caucasian        | 22 | ⋯ | Married           | 1 | Low    | 18 | Risk of Failure to Appear | 19.00 | 3 | Low  | New | 28 |\n",
       "| 50855 | 57181 | 51963 | PRETRIAL | DAYES    | DANIEL    | NA     | Male   | African-American | 22 | ⋯ | Single            | 4 | High   |  8 | Risk of Recidivism        |  0.18 | 8 | High | New | 18 |\n",
       "| 50855 | 57181 | 51963 | PRETRIAL | DAYES    | DANIEL    | NA     | Male   | African-American | 22 | ⋯ | Single            | 4 | High   | 18 | Risk of Failure to Appear | 13.00 | 1 | Low  | New | 18 |\n",
       "| 50850 | 57176 | 51958 | PRETRIAL | Debe     | Mikerlie  | George | Female | African-American | 22 | ⋯ | Significant Other | 2 | Medium | 18 | Risk of Failure to Appear | 11.00 | 1 | Low  | New | 18 |\n",
       "| 50839 | 57162 | 51945 | PRETRIAL | McLaurin | Stephanie | Nicole | Female | African-American | 22 | ⋯ | Single            | 1 | Low    | 18 | Risk of Failure to Appear | 16.00 | 2 | Low  | New | 27 |\n",
       "\n"
      ],
      "text/plain": [
       "  Person_ID AssessmentID Case_ID Agency_Text LastName FirstName MiddleName\n",
       "1 50844     57167        51950   PRETRIAL    Fisher   Kevin     NA        \n",
       "2 50848     57174        51956   PRETRIAL    KENDALL  KEVIN     NA        \n",
       "3 50855     57181        51963   PRETRIAL    DAYES    DANIEL    NA        \n",
       "4 50855     57181        51963   PRETRIAL    DAYES    DANIEL    NA        \n",
       "5 50850     57176        51958   PRETRIAL    Debe     Mikerlie  George    \n",
       "6 50839     57162        51945   PRETRIAL    McLaurin Stephanie Nicole    \n",
       "  Sex_Code_Text Ethnic_Code_Text ScaleSet_ID ⋯ MaritalStatus    \n",
       "1 Male          Caucasian        22          ⋯ Single           \n",
       "2 Male          Caucasian        22          ⋯ Married          \n",
       "3 Male          African-American 22          ⋯ Single           \n",
       "4 Male          African-American 22          ⋯ Single           \n",
       "5 Female        African-American 22          ⋯ Significant Other\n",
       "6 Female        African-American 22          ⋯ Single           \n",
       "  RecSupervisionLevel RecSupervisionLevelText Scale_ID\n",
       "1 1                   Low                     18      \n",
       "2 1                   Low                     18      \n",
       "3 4                   High                     8      \n",
       "4 4                   High                    18      \n",
       "5 2                   Medium                  18      \n",
       "6 1                   Low                     18      \n",
       "  DisplayText               RawScore DecileScore ScoreText AssessmentType Age\n",
       "1 Risk of Failure to Appear 15.00    1           Low       New            20 \n",
       "2 Risk of Failure to Appear 19.00    3           Low       New            28 \n",
       "3 Risk of Recidivism         0.18    8           High      New            18 \n",
       "4 Risk of Failure to Appear 13.00    1           Low       New            18 \n",
       "5 Risk of Failure to Appear 11.00    1           Low       New            18 \n",
       "6 Risk of Failure to Appear 16.00    2           Low       New            27 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c5d82-30d3-4610-9603-2b88cb47a0f4",
   "metadata": {},
   "source": [
    "> **What to look for in the output:**\n",
    "> - **Column names** such as `Person_ID`, `Case_ID`, `LastName`, `FirstName`, `MiddleName`, `Sex_Code_Text`, `Ethnic_Code_Text`, `RawScore`, `DecileScore`, `ScoreText`, `Age`  \n",
    "> - **Data types** (numeric vs. categorical) and any surprising or missing values  \n",
    "> - **Structure** of the dataset—how it's organized before we begin cleaning and analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d77e8f-8ed0-46b9-b032-7c628eb72df1",
   "metadata": {},
   "source": [
    "Now that we’ve successfully loaded the COMPAS dataset into our `df` object, it’s time to get a quick overview of its structure. In the next step, we’ll check how big the table is and see where any missing values might be hiding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59433cf-c225-400c-ba6d-580531c0e35e",
   "metadata": {},
   "source": [
    "#### Checking Dataset Size and Missing Data\n",
    "\n",
    "In this step, we first look at the overall size of our dataset and then count any empty or missing values:\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "324c5e82-7456-4d39-b3c0-71ba566b2de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spc_tbl_ [24,272 × 24] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n",
      " $ Person_ID              : num [1:24272] 50844 50848 50855 50855 50850 ...\n",
      " $ AssessmentID           : num [1:24272] 57167 57174 57181 57181 57176 ...\n",
      " $ Case_ID                : num [1:24272] 51950 51956 51963 51963 51958 ...\n",
      " $ Agency_Text            : chr [1:24272] \"PRETRIAL\" \"PRETRIAL\" \"PRETRIAL\" \"PRETRIAL\" ...\n",
      " $ LastName               : chr [1:24272] \"Fisher\" \"KENDALL\" \"DAYES\" \"DAYES\" ...\n",
      " $ FirstName              : chr [1:24272] \"Kevin\" \"KEVIN\" \"DANIEL\" \"DANIEL\" ...\n",
      " $ MiddleName             : chr [1:24272] NA NA NA NA ...\n",
      " $ Sex_Code_Text          : chr [1:24272] \"Male\" \"Male\" \"Male\" \"Male\" ...\n",
      " $ Ethnic_Code_Text       : chr [1:24272] \"Caucasian\" \"Caucasian\" \"African-American\" \"African-American\" ...\n",
      " $ ScaleSet_ID            : num [1:24272] 22 22 22 22 22 22 22 22 22 22 ...\n",
      " $ ScaleSet               : chr [1:24272] \"Risk and Prescreen\" \"Risk and Prescreen\" \"Risk and Prescreen\" \"Risk and Prescreen\" ...\n",
      " $ Language               : chr [1:24272] \"English\" \"English\" \"English\" \"English\" ...\n",
      " $ LegalStatus            : chr [1:24272] \"Pretrial\" \"Pretrial\" \"Pretrial\" \"Pretrial\" ...\n",
      " $ CustodyStatus          : chr [1:24272] \"Jail Inmate\" \"Jail Inmate\" \"Jail Inmate\" \"Jail Inmate\" ...\n",
      " $ MaritalStatus          : chr [1:24272] \"Single\" \"Married\" \"Single\" \"Single\" ...\n",
      " $ RecSupervisionLevel    : num [1:24272] 1 1 4 4 2 1 3 3 1 3 ...\n",
      " $ RecSupervisionLevelText: chr [1:24272] \"Low\" \"Low\" \"High\" \"High\" ...\n",
      " $ Scale_ID               : num [1:24272] 18 18 8 18 18 18 8 18 18 8 ...\n",
      " $ DisplayText            : chr [1:24272] \"Risk of Failure to Appear\" \"Risk of Failure to Appear\" \"Risk of Recidivism\" \"Risk of Failure to Appear\" ...\n",
      " $ RawScore               : num [1:24272] 15 19 0.18 13 11 16 0.71 24 19 0.38 ...\n",
      " $ DecileScore            : num [1:24272] 1 3 8 1 1 2 10 6 3 9 ...\n",
      " $ ScoreText              : chr [1:24272] \"Low\" \"Low\" \"High\" \"Low\" ...\n",
      " $ AssessmentType         : chr [1:24272] \"New\" \"New\" \"New\" \"New\" ...\n",
      " $ Age                    : num [1:24272] 20 28 18 18 18 27 28 28 46 19 ...\n",
      " - attr(*, \"spec\")=\n",
      "  .. cols(\n",
      "  ..   Person_ID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   AssessmentID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Case_ID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   Agency_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   LastName = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   FirstName = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   MiddleName = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Sex_Code_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Ethnic_Code_Text = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   ScaleSet_ID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   ScaleSet = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Language = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   LegalStatus = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   CustodyStatus = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   MaritalStatus = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   RecSupervisionLevel = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   RecSupervisionLevelText = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Scale_ID = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   DisplayText = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   RawScore = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   DecileScore = \u001b[32mcol_double()\u001b[39m,\n",
      "  ..   ScoreText = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   AssessmentType = \u001b[31mcol_character()\u001b[39m,\n",
      "  ..   Age = \u001b[32mcol_double()\u001b[39m\n",
      "  .. )\n",
      " - attr(*, \"problems\")=<externalptr> \n"
     ]
    }
   ],
   "source": [
    "str(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df2919-3a4f-4584-b48d-c68e75e4da6f",
   "metadata": {},
   "source": [
    "#### What `str(df)` Shows You\n",
    "\n",
    "\n",
    "- **Tibble [24,272 × 24]**  \n",
    "  Your data has **24,272 rows** (individual records) and **24 columns** (fields).\n",
    "\n",
    "- **Column lines**  \n",
    "  Each line looks like  \n",
    "  ```\n",
    "  $ ColumnName : type [1:24272] example values…\n",
    "  ```  \n",
    "  - **ColumnName**: the name of the field (e.g. `Person_ID`)  \n",
    "  - **type**: `num` means numbers, `chr` means text  \n",
    "  - **[1:24272]**: shows values exist for every row  \n",
    "  - **example values…**: the first few entries you’ll see\n",
    "\n",
    "- **`NA`** means a missing value (no data) in that spot.\n",
    "\n",
    "- **Why this matters**  \n",
    "  - You immediately know how big your dataset is  \n",
    "  - You see which columns are numeric vs text  \n",
    "  - You get a quick look at the first few values and spot missing entries before analysis  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2c324-914c-496d-bb8c-fbf72281b2b5",
   "metadata": {},
   "source": [
    "### 2.2 Handle Missing Values\n",
    "\n",
    "#### Counting Missing Values\n",
    "\n",
    "Let’s see which columns have missing data and how many blanks each contains:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb59cd4c-26fc-4f7e-abae-e2c774f6927c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiddleName  ScoreText        Age \n",
      "     17942         45         56 \n"
     ]
    }
   ],
   "source": [
    "# Count missing values per column\n",
    "missing <- colSums(is.na(df))\n",
    "\n",
    "# Show only columns that have any missing values\n",
    "cat(\"Missing values per column:\\n\")\n",
    "print(missing[missing > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cfc20b-de6c-41dd-90e7-265fa1cabd19",
   "metadata": {},
   "source": [
    "#### Options for Handling Missing Values\n",
    "- **Removal:** drop rows or columns with too many nulls  \n",
    "- **Imputation:** fill with mean/median or a constant  \n",
    "\n",
    "##### MiddleName: 17,942 missing values  \n",
    "  Most records don’t include a middle name—since this field isn’t critical to our analysis, we’ll drop the entire column.\n",
    "\n",
    "##### ScoreText: 45 missing values  \n",
    "  A small number of records lack the textual risk label. We’ll remove any rows where `ScoreText` is missing, since we need that label for downstream analyses.\n",
    "\n",
    "##### Age: 56 missing values\n",
    "  A handful of entries are missing age information. Since age is important for our analysis, we’ll impute these missing ages with the median age value.\n",
    "\n",
    "By printing only `missing[missing > 0]`, we focus on the columns that actually have missing entries, allowing us to target our cleaning efforts precisely.  \n",
    "\n",
    "Below we’ll:\n",
    "1. Drop columns with >50% missing  \n",
    "2. Impute `Age` with the median  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073dce7f-892f-4b04-9802-6c50fadf15ff",
   "metadata": {},
   "source": [
    "##### Step 1: Drop Mostly Empty Columns\n",
    "\n",
    "Our dataset has a “MiddleName\" column that’s almost entirely blank. To avoid clutter, we remove any column where more than half of its values are missing. This will automatically drop “MiddleName” and any other mostly empty fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c35aa48-f091-4424-8cc7-9aa9539519a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the minimum non-missing entries (50% of rows)\n",
    "threshold <- nrow(df) * 0.5\n",
    "\n",
    "# Keep only columns with at least 'threshold' non-NA values\n",
    "df <- df[, colSums(!is.na(df)) >= threshold]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad01b8d-5dc0-4a65-9b3e-b3a7272bd951",
   "metadata": {},
   "source": [
    "##### Step 2: Remove Rows with Blank `ScoreText` and Fill Missing `Age`\n",
    "\n",
    "First, we drop any rows where `ScoreText` is blank, since those entries don’t tell us whether someone was classified as “Low,” “Medium,” or “High” risk. After that, we flag rows with missing `Age`, compute the median age, and fill those gaps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b63de2c-8a4a-4104-a955-254f184bc2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove rows where ScoreText is blank\n",
    "df <- df[trimws(df$ScoreText) != \"\", ]\n",
    "\n",
    "# 2. Flag rows where Age was missing\n",
    "df$age_missing <- is.na(df$Age)\n",
    "\n",
    "# 3. Compute median Age and fill missing values\n",
    "median_age <- median(df$Age, na.rm = TRUE)\n",
    "df$Age[is.na(df$Age)] <- median_age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba3fc8c-3f76-4d1c-be22-1a07c9bdd890",
   "metadata": {},
   "source": [
    "##### Now we have:\n",
    "- Removed all rows lacking a valid risk category in `ScoreText`.  \n",
    "- Marked originally missing `Age` values in a new `age_missing` column.  \n",
    "- Filled those missing ages with the dataset’s median age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4469422c-a706-45a1-99ae-d6818f2d888b",
   "metadata": {},
   "source": [
    "### 2.3 Validate & Correct Data Types\n",
    "\n",
    "Before we go further, let’s make sure each column uses the right data type:\n",
    "\n",
    "- Numbers as integers or floats  \n",
    "- Dates as datetime objects  \n",
    "- Text fields we’ll analyze categorically as “category”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbd2fa8-70a7-44ac-80d6-5c9577d80619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tibble [24,272 × 24] (S3: tbl_df/tbl/data.frame)\n",
      " $ Person_ID              : num [1:24272] 50844 50848 50855 50855 50850 ...\n",
      " $ AssessmentID           : num [1:24272] 57167 57174 57181 57181 57176 ...\n",
      " $ Case_ID                : num [1:24272] 51950 51956 51963 51963 51958 ...\n",
      " $ Agency_Text            : chr [1:24272] \"PRETRIAL\" \"PRETRIAL\" \"PRETRIAL\" \"PRETRIAL\" ...\n",
      " $ LastName               : chr [1:24272] \"Fisher\" \"KENDALL\" \"DAYES\" \"DAYES\" ...\n",
      " $ FirstName              : chr [1:24272] \"Kevin\" \"KEVIN\" \"DANIEL\" \"DANIEL\" ...\n",
      " $ Sex_Code_Text          : Factor w/ 2 levels \"Female\",\"Male\": 2 2 2 2 1 1 2 2 1 2 ...\n",
      " $ Ethnic_Code_Text       : Factor w/ 9 levels \"African-Am\",\"African-American\",..: 5 5 2 2 2 2 6 6 5 2 ...\n",
      " $ ScaleSet_ID            : num [1:24272] 22 22 22 22 22 22 22 22 22 22 ...\n",
      " $ ScaleSet               : chr [1:24272] \"Risk and Prescreen\" \"Risk and Prescreen\" \"Risk and Prescreen\" \"Risk and Prescreen\" ...\n",
      " $ Language               : Factor w/ 2 levels \"English\",\"Spanish\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ LegalStatus            : chr [1:24272] \"Pretrial\" \"Pretrial\" \"Pretrial\" \"Pretrial\" ...\n",
      " $ CustodyStatus          : chr [1:24272] \"Jail Inmate\" \"Jail Inmate\" \"Jail Inmate\" \"Jail Inmate\" ...\n",
      " $ MaritalStatus          : Factor w/ 7 levels \"Divorced\",\"Married\",..: 5 2 5 5 4 5 5 5 5 5 ...\n",
      " $ RecSupervisionLevel    : num [1:24272] 1 1 4 4 2 1 3 3 1 3 ...\n",
      " $ RecSupervisionLevelText: Factor w/ 4 levels \"High\",\"Low\",\"Medium\",..: 2 2 1 1 3 2 4 4 2 4 ...\n",
      " $ Scale_ID               : num [1:24272] 18 18 8 18 18 18 8 18 18 8 ...\n",
      " $ DisplayText            : chr [1:24272] \"Risk of Failure to Appear\" \"Risk of Failure to Appear\" \"Risk of Recidivism\" \"Risk of Failure to Appear\" ...\n",
      " $ RawScore               : int [1:24272] 15 19 0 13 11 16 0 24 19 0 ...\n",
      " $ DecileScore            : int [1:24272] 1 3 8 1 1 2 10 6 3 9 ...\n",
      " $ ScoreText              : Factor w/ 3 levels \"High\",\"Low\",\"Medium\": 2 2 1 2 2 2 1 3 2 1 ...\n",
      " $ AssessmentType         : chr [1:24272] \"New\" \"New\" \"New\" \"New\" ...\n",
      " $ Age                    : int [1:24272] 20 28 18 18 18 27 28 28 46 19 ...\n",
      " $ age_missing            : logi [1:24272] FALSE FALSE FALSE FALSE FALSE FALSE ...\n"
     ]
    }
   ],
   "source": [
    "# 1. Convert RawScore, DecileScore and Age to integers\n",
    "df$RawScore    <- as.integer(df$RawScore)\n",
    "df$DecileScore <- as.integer(df$DecileScore)\n",
    "df$Age         <- as.integer(df$Age)\n",
    "\n",
    "# 2. Convert text fields to factors\n",
    "text_cols <- c(\n",
    "  \"ScoreText\", \"Sex_Code_Text\", \"Ethnic_Code_Text\",\n",
    "  \"Language\", \"MaritalStatus\", \"RecSupervisionLevelText\"\n",
    ")\n",
    "df[text_cols] <- lapply(df[text_cols], factor)\n",
    "\n",
    "# 4. Verify types\n",
    "str(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b49c47-a2fa-43da-909e-9590c65ba2b0",
   "metadata": {},
   "source": [
    "> **What we’ve done:**  \n",
    "> - Forced `RawScore`, `DecileScore`, and `Age` into integer form   \n",
    "> - Marked risk categories and demographic fields as categorical  \n",
    "> - Verified the changes by once again inspecting the structure of the 'df' dataframe "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98647b2c-ad22-42c6-922c-96362cb090be",
   "metadata": {},
   "source": [
    "### Step 2.4: Find and Remove Extreme Values (Outliers) in `RawScore`\n",
    "\n",
    "Even smart data can hide a few extreme values—called **outliers**—that skew our insights. We’ll clean those out by:\n",
    "\n",
    "1. **Sorting** all `RawScore` values and finding the 25th percentile (Q1) and 75th percentile (Q3).  \n",
    "2. Calculating the **interquartile range (IQR)** = Q3 − Q1, which covers the middle 50% of the data.  \n",
    "3. Defining an **acceptable range** as   [Q1 − 3×IQR, Q3 + 3×IQR]\n",
    "4. **Keeping** only rows with `RawScore` inside that range and dropping the rest.\n",
    "\n",
    "This preserves most of the data while removing the very highest or lowest scores that could mislead our analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8972d75-d13f-4121-8c8d-056a3eb33c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before cleaning:  24272 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after removing outliers:  24263 \n"
     ]
    }
   ],
   "source": [
    "# 1. Calculate Q1 (25th percentile) and Q3 (75th percentile) for RawScore\n",
    "Q1 <- quantile(df$RawScore, 0.25, na.rm = TRUE)\n",
    "Q3 <- quantile(df$RawScore, 0.75, na.rm = TRUE)\n",
    "\n",
    "# 2. Compute the IQR\n",
    "IQR_value <- Q3 - Q1\n",
    "\n",
    "# 3. Define acceptable lower and upper bounds\n",
    "lower_bound <- Q1 - 3 * IQR_value\n",
    "upper_bound <- Q3 + 3 * IQR_value\n",
    "\n",
    "# 4. Filter the data frame to keep only non-outliers\n",
    "df_clean <- df[df$RawScore >= lower_bound & df$RawScore <= upper_bound, ]\n",
    "\n",
    "# 5. Report how many rows we kept versus removed\n",
    "cat(\"Rows before cleaning: \", nrow(df), \"\\n\")\n",
    "cat(\"Rows after removing outliers: \", nrow(df_clean), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5cf053-925e-4a9c-a16b-d53afbfbaf1a",
   "metadata": {},
   "source": [
    "> **In plain terms:**  \n",
    "> - We measured how wide the middle 50% of scores is.  \n",
    "> - We dropped any scores more than three times that range away from the center.  \n",
    "> - Now `df_clean` has most of our original rows minus the extreme cases that could distort averages or trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cefd5b-06a7-4069-83d7-bdf45e5da891",
   "metadata": {},
   "source": [
    "### Step 2.5: Standardize & Normalize Key Variables\n",
    "\n",
    "Some analysis methods work best when numbers share a common scale. In R we can use:\n",
    "\n",
    "- **`scale()`** for z-score standardization  \n",
    "- A simple formula for min-max scaling  \n",
    "\n",
    "Here’s what we’ll do on our cleaned data frame `df_clean`:\n",
    "\n",
    "1. **Z-score Standardization** of `Age`  \n",
    "   - Subtract the mean age, then divide by the standard deviation  \n",
    "   - Creates a new column `age_z` where most values fall between –3 and +3  \n",
    "\n",
    "2. **Min-Max Scaling** of `RawScore`  \n",
    "   - Rescales values to lie between 0 (lowest score) and 1 (highest score)  \n",
    "   - Creates a new column `rawscore_scaled` that preserves relative differences  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44c17dc9-dc10-487b-a632-edcb57cea2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Age</th><th scope=col>age_z</th><th scope=col>RawScore</th><th scope=col>rawscore_scaled</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>20</td><td>-1.0581198</td><td>15</td><td>0.3333333</td></tr>\n",
       "\t<tr><td>28</td><td>-0.3877174</td><td>19</td><td>0.4222222</td></tr>\n",
       "\t<tr><td>18</td><td>-1.2257204</td><td> 0</td><td>0.0000000</td></tr>\n",
       "\t<tr><td>18</td><td>-1.2257204</td><td>13</td><td>0.2888889</td></tr>\n",
       "\t<tr><td>18</td><td>-1.2257204</td><td>11</td><td>0.2444444</td></tr>\n",
       "\t<tr><td>27</td><td>-0.4715177</td><td>16</td><td>0.3555556</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 4\n",
       "\\begin{tabular}{llll}\n",
       " Age & age\\_z & RawScore & rawscore\\_scaled\\\\\n",
       " <int> & <dbl> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 20 & -1.0581198 & 15 & 0.3333333\\\\\n",
       "\t 28 & -0.3877174 & 19 & 0.4222222\\\\\n",
       "\t 18 & -1.2257204 &  0 & 0.0000000\\\\\n",
       "\t 18 & -1.2257204 & 13 & 0.2888889\\\\\n",
       "\t 18 & -1.2257204 & 11 & 0.2444444\\\\\n",
       "\t 27 & -0.4715177 & 16 & 0.3555556\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 4\n",
       "\n",
       "| Age &lt;int&gt; | age_z &lt;dbl&gt; | RawScore &lt;int&gt; | rawscore_scaled &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| 20 | -1.0581198 | 15 | 0.3333333 |\n",
       "| 28 | -0.3877174 | 19 | 0.4222222 |\n",
       "| 18 | -1.2257204 |  0 | 0.0000000 |\n",
       "| 18 | -1.2257204 | 13 | 0.2888889 |\n",
       "| 18 | -1.2257204 | 11 | 0.2444444 |\n",
       "| 27 | -0.4715177 | 16 | 0.3555556 |\n",
       "\n"
      ],
      "text/plain": [
       "  Age age_z      RawScore rawscore_scaled\n",
       "1 20  -1.0581198 15       0.3333333      \n",
       "2 28  -0.3877174 19       0.4222222      \n",
       "3 18  -1.2257204  0       0.0000000      \n",
       "4 18  -1.2257204 13       0.2888889      \n",
       "5 18  -1.2257204 11       0.2444444      \n",
       "6 27  -0.4715177 16       0.3555556      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# 1. Z-score standardization on Age\n",
    "df_clean$age_z <- as.numeric(scale(df_clean$Age))\n",
    "\n",
    "# 2. Min-Max scaling on RawScore\n",
    "raw_min <- min(df_clean$RawScore, na.rm = TRUE)\n",
    "raw_max <- max(df_clean$RawScore, na.rm = TRUE)\n",
    "df_clean$rawscore_scaled <- (df_clean$RawScore - raw_min) / (raw_max - raw_min)\n",
    "\n",
    "# 3. Peek at the new columns\n",
    "head(df_clean[, c(\"Age\", \"age_z\", \"RawScore\", \"rawscore_scaled\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351f1ed4-8ee3-4733-9210-0d9d37cf653d",
   "metadata": {},
   "source": [
    "## Interpreting Our Transformed Data\n",
    "\n",
    "\n",
    "\n",
    "| Age | age_z | RawScore | rawscore_scaled |\n",
    "| --- | ----- | -------- | --------------- |\n",
    "| 20  | -1.057784 | 15       | 0.3333      |\n",
    "| 28  | -0.387237 | 19       | 0.4222      |\n",
    "| 18  | -1.225421 | 0        | 0.0000      |\n",
    "| 18  | -1.225421 | 13       | 0.2888      |\n",
    "\n",
    "### What each column is\n",
    "\n",
    "- **Age**  \n",
    "  The actual age in years\n",
    "\n",
    "- **age_z**  \n",
    "  A “z‑score” shows how far each age is from the average age, measured in standard units  \n",
    "  - 0 means exactly average  \n",
    "  - Negative means below average  \n",
    "  - Positive means above average  \n",
    "  - −-1.05778 means about -1.05778 units younger than average\n",
    "\n",
    "- **RawScore**  \n",
    "  The original score before any changes (for example a test result or rating)\n",
    "\n",
    "- **rawscore_scaled**  \n",
    "  The RawScore rescaled to lie between 0 and 1  \n",
    "  - 0 is the lowest RawScore in our group  \n",
    "  - 1 is the highest RawScore in our group  \n",
    "  - 0.03 means very close to the lowest  \n",
    "  - 0.29 means 29 percent of the way from lowest to highest\n",
    "\n",
    "### Why we do this\n",
    "\n",
    "1. **Fair comparison**  \n",
    "   When columns use very different units or ranges our analysis can get biased. Standardizing and scaling puts all numbers on the same footing.\n",
    "\n",
    "2. **Better results**  \n",
    "   Many data tools and machine learning methods work best when inputs live on the same scale.\n",
    "\n",
    "3. **Clear interpretation**  \n",
    "   - Z‑scores tell us how far a value is from the average in comparable units  \n",
    "   - Scaled scores between 0 and 1 make it easy to see relative position without worrying about original units\n",
    "\n",
    "---\n",
    "\n",
    "In plain terms, we’ve “translated” every number so they all speak the same language. That helps our next analysis steps work properly and gives you a fair way to compare apples to apples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcf873a-a762-4602-83cb-359a57127104",
   "metadata": {},
   "source": [
    "### Step 2.6: Record Your Cleaning Steps\n",
    "\n",
    "Finally, it’s best practice to keep a log of every transformation. Below we build a simple dictionary summarizing what we did:\n",
    "\n",
    "- Which columns we dropped because they were mostly empty  \n",
    "- The median age we used for imputation  \n",
    "- The bounds we used to remove outliers in `RawScore`  \n",
    "- Which columns we standardized and normalized  \n",
    "\n",
    "At the end, we print this log in a clear, readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67445ad6-637e-42d2-9d88-1da98ac7d5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Step      Details\n",
      "1           Dropped Columns   MiddleName\n",
      "2               Imputed Age           29\n",
      "3 Outlier Bounds (RawScore)      -11, 45\n",
      "4              Standardized        age_z\n",
      "5                Normalized rawscore....\n"
     ]
    }
   ],
   "source": [
    "# 1. Define each step and its details\n",
    "steps <- c(\n",
    "  \"Dropped Columns\",\n",
    "  \"Imputed Age\",\n",
    "  \"Outlier Bounds (RawScore)\",\n",
    "  \"Standardized\",\n",
    "  \"Normalized\"\n",
    ")\n",
    "\n",
    "details <- list(\n",
    "  names(missing[missing > threshold]),      # columns dropped\n",
    "  median_age,                               # age used for imputation\n",
    "  c(lower_bound, upper_bound),              # outlier bounds\n",
    "  \"age_z\",                                  # standardized column\n",
    "  \"rawscore_scaled\"                         # normalized column\n",
    ")\n",
    "\n",
    "# 2. Assemble into a data frame with a list-column\n",
    "log_df <- data.frame(\n",
    "  Step    = steps,\n",
    "  Details = I(details),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "# 3. Display the log\n",
    "print(log_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81d6d4-01bc-4f52-aa3b-dfa8a5834808",
   "metadata": {},
   "source": [
    " **How to read this table:**  \n",
    " - **Step:** what we did  \n",
    " - **Details:** the exact values or columns affected by that step  \n",
    "\n",
    "\n",
    "> **Why this matters:**  \n",
    "> A clear transformation log makes your work reproducible and lets others (or future you) understand exactly how the data was prepared before any analysis or modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b4d4b6-cecc-46fa-8773-421993a6cae5",
   "metadata": {},
   "source": [
    "## Next Steps: Continue in R or Switch to Python\n",
    "\n",
    "Our data is now clean and properly formatted. You have two options:\n",
    "\n",
    "1. **Try the Python version** of this cleaning workflow by opening `02_data_cleaning_Python.ipynb`.  \n",
    "2. **Move on to summary statistics in R** by opening `03_summary_statistics_R.ipynb`.  \n",
    "\n",
    "Choose the notebook that matches your preferred language, and let’s continue exploring our recidivism dataset!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a90119-1c21-4746-871f-a4195540a1a1",
   "metadata": {},
   "source": [
    "# 03: Summary Statistics\n",
    "\n",
    "**Objective:** Quickly summarize your data’s center, spread, and shape so you can spot patterns and anomalies before diving deeper.\n",
    "\n",
    "**Key Steps:**\n",
    "<table width=\"100%\">\n",
    "  <tr>\n",
    "    <td style=\"vertical-align: top; text-align: left; width: 60%; padding-right: 20px;\">\n",
    "      <ol style=\"font-size: 20px; line-height: 1.4;\">\n",
    "        <li>Compute central tendency (mean, median, mode)</li>\n",
    "        <li>Measure dispersion (range, variance, standard deviation, IQR)</li>\n",
    "        <li>Assess distribution shape (skewness, kurtosis)</li>\n",
    "        <li>Detect anomalies or outliers early </li>\n",
    "      </ol>\n",
    "    </td>\n",
    "    <td style=\"vertical-align: top; text-align: left; width: 40%;\">\n",
    "      <!-- relative path to cleaning.png -->\n",
    "      <img src=\"../slides/sum stats.png\" alt=\"summary stats\" width=\"1000\" />\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "---\n",
    "<audio controls src=\"../audio/summary.m4a\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f55777e-9aa9-435b-82a7-5eba400c4c86",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary Statistics: Step-by-Step\n",
    "\n",
    "We’ll walk through calculating key summary statistics on our COMPAS dataset in both R and Python. Each step includes:\n",
    "\n",
    "1. **What we’re doing** (plain English)  \n",
    "2. **Code to run**  \n",
    "3. **What the output tells you**\n",
    "\n",
    "#### Review: Loading the Data\n",
    "\n",
    "Reload the COMPAS CSV into our table `df`, which contains **24,272 rows** and **24 columns**. With the data in `df`, we’re ready to compute our summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82320171-866e-4736-9dcc-bb82ca3674b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/compas_scores_raw.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12201e72-982b-48eb-892f-94c9488fce79",
   "metadata": {},
   "source": [
    "#### Step 1: Compute the Mean (Average)\n",
    "\n",
    "The mean tells us the “typical” value by adding up all values and dividing by the count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0a30f0-dcda-4ad8-9520-95a008fa4ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.557258569545157\n"
     ]
    }
   ],
   "source": [
    "mean_raw = df[\"RawScore\"].mean()\n",
    "print(mean_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacda161-6c99-4660-a151-054b6b97649c",
   "metadata": {},
   "source": [
    "**What you’ll see:**  \n",
    "A single number (in this case, `15.557`). This is the center of your RawScore distribution. If it is positive, scores tend to be above zero; if negative, below.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c28f789-c03f-4959-8a25-3ccf1095c91b",
   "metadata": {},
   "source": [
    "#### Step 2: Find the Median\n",
    "\n",
    "The **median** is the middle value when you sort all the numbers. It’s less affected by extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508d8398-1868-407b-b3e9-0994b89bccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0\n"
     ]
    }
   ],
   "source": [
    "median_raw = df[\"RawScore\"].median()\n",
    "print(median_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca9144-a538-4ddf-a0fc-2631564fcb7e",
   "metadata": {},
   "source": [
    "**What you’ll see:**  \n",
    "- One number (for example, `16`).  \n",
    "- This is the “middle” score: 50% of your data are below it and 50% are above it.  \n",
    "- If this middle number is very different from the average you calculated before, it means your data are lopsided—more values bunch up on one side than the other.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c9883a-54bd-47ec-b5db-648bec9022ae",
   "metadata": {},
   "source": [
    "#### Step 3: Get the Mode\n",
    "\n",
    "The **mode** is the value that appears most often in your data. It highlights the single most common observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f1f036-b08c-4091-a7a8-76fad1b9017f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "mode_raw = df[\"RawScore\"].mode()[0]\n",
    "print(mode_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9738339-f77c-420a-9932-442415355e68",
   "metadata": {},
   "source": [
    "\n",
    "**What you’ll see:**  \n",
    "A single number (for example, `13`) — the RawScore value that occurs more frequently than any other. This indicates the most typical individual score in your dataset.\n",
    "\n",
    "**Why it’s useful:**  \n",
    "- **Identifies the peak** of your distribution, showing where data cluster most densely.  \n",
    "- **Complements mean and median**, especially when your data are skewed or have multiple peaks.  \n",
    "- **Helps with categorical data**, by revealing the most popular category or choice.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18af055a-dee3-42bc-8ad0-16a5c9afe45a",
   "metadata": {},
   "source": [
    "#### Step 4: Measure How Spread Out Your Data Are\n",
    "\n",
    "We want to know not just the “middle” of our scores but how far apart they are. We’ll use three measures:\n",
    "\n",
    "- **Range**: the gap between the smallest and largest value  \n",
    "- **Variance**: the average of squared differences from the mean (gets bigger when values are more spread out)  \n",
    "- **Standard Deviation (SD)**: the square root of the variance, which tells you in the same units how far values typically fall from the mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45058718-2c23-42eb-a581-2a3c9226c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 51.0 70.38655796568817 8.389669717318327\n"
     ]
    }
   ],
   "source": [
    "min_raw = df[\"RawScore\"].min()\n",
    "max_raw = df[\"RawScore\"].max()\n",
    "var_raw = df[\"RawScore\"].var()\n",
    "sd_raw  = df[\"RawScore\"].std()\n",
    "print(min_raw, max_raw, var_raw, sd_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe87c5-9d61-442d-a3ab-2e40b0c6e382",
   "metadata": {},
   "source": [
    "**What you’ll see:** \n",
    "\n",
    "- **Range: 0.01 to 51**  \n",
    "  The lowest score is 0.01, the highest is 51—a span of about 51 points. This tells you there are both extremely low and extremely high risk assessments in your data.\n",
    "\n",
    "- **Variance: 70.3866**  \n",
    "  Variance squares each deviation from the mean, so this large number confirms the scores are widely spread out.\n",
    "\n",
    "- **Standard deviation: 8.3897**  \n",
    "  By taking the square root of the variance, we get back to the original units: on average, a RawScore lies about 10 points away from the mean. A high SD signals substantial variability in individual risk levels.\n",
    "\n",
    "**Why it matters:**  \n",
    "- Such a wide range and high spread mean outliers can heavily influence analyses.  \n",
    "- Before modeling, you’ll often standardize or normalize these scores so each case is treated fairly by downstream algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcb803-45b1-4164-8e07-cd44fc9aadc4",
   "metadata": {},
   "source": [
    "#### Quick Overall Summary\n",
    "\n",
    "Now that we’ve calculated each statistic separately, we can use one command to get them all at once. This gives you a fast “at-a-glance” view of your data’s key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c578687-2390-4b07-a51d-56d174b5b5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24272.000000\n",
       "mean        15.557259\n",
       "std          8.389670\n",
       "min          0.010000\n",
       "25%         13.000000\n",
       "50%         16.000000\n",
       "75%         21.000000\n",
       "max         51.000000\n",
       "Name: RawScore, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"RawScore\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31222b62-faf8-4dfa-8cae-43c714091496",
   "metadata": {},
   "source": [
    "**What you’ll see:** \n",
    "\n",
    "- **count** – how many valid (non-missing) scores were included in the calculation  \n",
    "- **mean** – the average score, calculated by summing all scores and dividing by the number of scores  \n",
    "- **3rd Qu.** – the 75th percentile, meaning 75% of the scores fall below this point   \n",
    "- **std** – the standard deviation, telling you how far scores typically vary from the average  \n",
    "- **min** - the lowest score in your data, showing the smallest value recorded\n",
    "- **25%** - the 25th percentile, meaning 25% of the scores fall below this point\n",
    "- **50%** - the 50th percentile, the “middle” score where half the values are below and half above  \n",
    "- **75%** - the 75th percentile, meaning 75% of the scores fall below this point\n",
    "- **max** – the highest score in your data, showing the largest value recorded \n",
    "\n",
    "**Why it matters:**  \n",
    "This one-line summary gives you a quick snapshot of where your data cluster (center), how much they vary (spread), and the key cutoff points (percentiles). It’s an essential sanity check before creating charts or running more advanced analyses.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f031bb-1091-4873-a4e7-5e3cc0e4e185",
   "metadata": {},
   "source": [
    "#### Step 5: Assess Distribution Shape (Skewness & Kurtosis)\n",
    "\n",
    "We want to know whether our RawScore values are symmetrically distributed or lopsided, and whether they have heavy tails or are more tightly clustered than a normal bell curve.\n",
    "\n",
    "---\n",
    "\n",
    "**What we’re doing in plain English**  \n",
    "- **Skewness** measures asymmetry:  \n",
    "  - A **positive** skewness means a longer right tail (more extreme high scores).  \n",
    "  - A **negative** skewness means a longer left tail (more extreme low scores).  \n",
    "- **Kurtosis** measures “tailedness”:  \n",
    "  - A **high** kurtosis (> 3) means heavy tails and more outliers than a normal distribution.  \n",
    "  - A **low** kurtosis (< 3) means light tails and fewer outliers.\n",
    "---\n",
    "\n",
    "> **Import `skew` and `kurtosis` from SciPy**  \n",
    "> The `scipy.stats` module provides reliable, ready-to-use functions for calculating skewness and kurtosis. By importing `skew` and `kurtosis`, we can easily measure our data’s asymmetry and tail heaviness without writing these complex calculations from scratch.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58c34847-220f-4def-bc6c-d1420d1a0489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness: -0.29380581309483567\n",
      "Kurtosis: 3.068529734911468\n"
     ]
    }
   ],
   "source": [
    "# compute skewness & kurtosis using SciPy\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "skew_raw = skew(df[\"RawScore\"])\n",
    "# fisher=False gives the “plain” kurtosis; normal distribution → 3\n",
    "kurt_raw = kurtosis(df[\"RawScore\"], fisher=False)\n",
    "\n",
    "print(\"Skewness:\", skew_raw)\n",
    "print(\"Kurtosis:\", kurt_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5b9081-8a46-4cee-a688-f1a6952826bc",
   "metadata": {},
   "source": [
    "#### Interpreting Skewness and Kurtosis\n",
    "\n",
    "- **Skewness: -0.294**  \n",
    "A negative value means the distribution has a longer left tail. In plain terms most scores cluster on the right but a few unusually low scores stretch out to the left\n",
    "\n",
    "- **Kurtosis: 3**  \n",
    "A value of 3 matches the “normal” bell curve. This tells you your data have about the expected number of outliers—no unusually heavy or light tails.\n",
    "\n",
    "**Why it matters**  \n",
    "- Slight left skew (–0.2938) indicates the distribution is close to symmetric, so you likely don’t need to transform or trim low-end scores unless your analysis demands very strict symmetry.\n",
    "- Normal kurtosis (3) means you don’t have more extreme values than usual, so outlier counts are typical.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e253704-31f8-4590-89b1-ff1fd2c06978",
   "metadata": {},
   "source": [
    "## Next Steps: Data Visualization\n",
    "\n",
    "We’ve completed our summary statistics and are ready to see the data in action. Choose your path:\n",
    "\n",
    "1. **Visualize in R** by opening `04_data_visualization_R.ipynb`  \n",
    "2. **Visualize in Python** by opening `04_data_visualization_Python.ipynb`  \n",
    "\n",
    "Pick the notebook for your preferred language and let’s start creating charts to uncover patterns in our recidivism data!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa42af-bb8e-467f-a22f-285bb0ddc54d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}